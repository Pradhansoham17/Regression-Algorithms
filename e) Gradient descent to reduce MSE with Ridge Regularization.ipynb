{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  2  1\n",
       "1  3  2\n",
       "2  1  2\n",
       "3  1  1\n",
       "4  0  1\n",
       "5  5  3\n",
       "6  4  3\n",
       "7  6  7\n",
       "8  5  6\n",
       "9  3  5"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('C:\\\\Users\\\\soham\\\\Downloads\\\\LinearRegression.csv')\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21606"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MeanSquaredError(Y_true,Y_pred):\n",
    "    MSE = np.square(np.subtract(Y_true,Y_pred)).mean() \n",
    "    return MSE\n",
    "\n",
    "Y_true = [1,1,2,2,4]\n",
    "Y_pred = [0.6,1.29,1.99,2.69,3.4]\n",
    "\n",
    "MeanSquaredError(Y_true,Y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_regularization(X, y_true, lr=0.05, epoch=100, lamda=0.1): #updating m and c till fixed number of iteration/epoch,by default epoch=100\n",
    "    \n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    '''\n",
    "    \n",
    "    m, c = 3,2 # parameters\n",
    "    logs, mse = [], [] # lists to store learning process\n",
    "    N = len(X) # number of samples\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "        y_pred = (m*X + c)\n",
    "        diff = y_pred - y_true \n",
    "        \n",
    "        MSE= MeanSquaredError(y_true, y_pred)\n",
    "        print('The Mean Squared Error of epoch ',i,' is ',MSE)\n",
    "        \n",
    "        logs.append((m, c))\n",
    "        mse.append(MSE)\n",
    "        \n",
    "        # lists for plotting purposes\n",
    "        mse_list.append(MSE)\n",
    "        m_list.append(m)\n",
    "        c_list.append(c)\n",
    "        \n",
    "        m -= lr * ((2 * np.dot(X,diff).sum() / N) + 2*lamda*m)  # acc to gradient descent eqn, this is m(new) = (m(old) + α * ∂(MSE)/∂m ) , where α is learning rate\n",
    "        # added the regularization factor '2*lamda*m', in the calculation of ∂(MSE)/∂m, no changes in clculation of 'c'\n",
    "        c -= lr * (2 * diff.sum() / N)  # acc to gradient descent eqn, this is c(new) = (c(old) + α * ∂(MSE)/∂c ) , where α is learning rate\n",
    "        \n",
    "    print('The Final Value of m is : ',m)\n",
    "    print('The Final Value of c is : ',c)\n",
    "    print('The Minimum Value of MSE is : ',min(mse))\n",
    "    \n",
    "           \n",
    "    return logs, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error of epoch  0  is  79.9\n",
      "The Mean Squared Error of epoch  1  is  43.4972424\n",
      "The Mean Squared Error of epoch  2  is  24.032420540646395\n",
      "The Mean Squared Error of epoch  3  is  13.62700659893446\n",
      "The Mean Squared Error of epoch  4  is  8.066259288284364\n",
      "The Mean Squared Error of epoch  5  is  5.095662793659487\n",
      "The Mean Squared Error of epoch  6  is  3.509414965827829\n",
      "The Mean Squared Error of epoch  7  is  2.6627275460350885\n",
      "The Mean Squared Error of epoch  8  is  2.210896671512855\n",
      "The Mean Squared Error of epoch  9  is  1.9697088347121352\n",
      "The Mean Squared Error of epoch  10  is  1.8407661456197855\n",
      "The Mean Squared Error of epoch  11  is  1.7715443152817563\n",
      "The Mean Squared Error of epoch  12  is  1.734031882379788\n",
      "The Mean Squared Error of epoch  13  is  1.7133090868972272\n",
      "The Mean Squared Error of epoch  14  is  1.7014430829133538\n",
      "The Mean Squared Error of epoch  15  is  1.6942261698845797\n",
      "The Mean Squared Error of epoch  16  is  1.6894340261895509\n",
      "The Mean Squared Error of epoch  17  is  1.6858963394742237\n",
      "The Mean Squared Error of epoch  18  is  1.683001446414071\n",
      "The Mean Squared Error of epoch  19  is  1.6804326931831368\n",
      "The Mean Squared Error of epoch  20  is  1.6780284093243094\n",
      "The Mean Squared Error of epoch  21  is  1.6757077479114204\n",
      "The Mean Squared Error of epoch  22  is  1.6734315658542354\n",
      "The Mean Squared Error of epoch  23  is  1.6711819038709064\n",
      "The Mean Squared Error of epoch  24  is  1.6689513089080212\n",
      "The Mean Squared Error of epoch  25  is  1.666737342427778\n",
      "The Mean Squared Error of epoch  26  is  1.6645398043972157\n",
      "The Mean Squared Error of epoch  27  is  1.662359367013109\n",
      "The Mean Squared Error of epoch  28  is  1.6601969309384512\n",
      "The Mean Squared Error of epoch  29  is  1.6580533448199037\n",
      "The Mean Squared Error of epoch  30  is  1.6559293020948456\n",
      "The Mean Squared Error of epoch  31  is  1.6538253201326376\n",
      "The Mean Squared Error of epoch  32  is  1.6517417542479542\n",
      "The Mean Squared Error of epoch  33  is  1.6496788236432358\n",
      "The Mean Squared Error of epoch  34  is  1.6476366388020274\n",
      "The Mean Squared Error of epoch  35  is  1.645615226044304\n",
      "The Mean Squared Error of epoch  36  is  1.6436145479146975\n",
      "The Mean Squared Error of epoch  37  is  1.6416345194002229\n",
      "The Mean Squared Error of epoch  38  is  1.6396750204943733\n",
      "The Mean Squared Error of epoch  39  is  1.637735905764234\n",
      "The Mean Squared Error of epoch  40  is  1.6358170115504862\n",
      "The Mean Squared Error of epoch  41  is  1.6339181613414422\n",
      "The Mean Squared Error of epoch  42  is  1.6320391697602026\n",
      "The Mean Squared Error of epoch  43  is  1.6301798455094647\n",
      "The Mean Squared Error of epoch  44  is  1.6283399935386318\n",
      "The Mean Squared Error of epoch  45  is  1.6265194166336592\n",
      "The Mean Squared Error of epoch  46  is  1.6247179165799928\n",
      "The Mean Squared Error of epoch  47  is  1.6229352950106448\n",
      "The Mean Squared Error of epoch  48  is  1.621171354022486\n",
      "The Mean Squared Error of epoch  49  is  1.619425896622174\n",
      "The Mean Squared Error of epoch  50  is  1.6176987270470051\n",
      "The Mean Squared Error of epoch  51  is  1.6159896509940122\n",
      "The Mean Squared Error of epoch  52  is  1.6142984757818195\n",
      "The Mean Squared Error of epoch  53  is  1.6126250104632445\n",
      "The Mean Squared Error of epoch  54  is  1.6109690659018512\n",
      "The Mean Squared Error of epoch  55  is  1.609330454822158\n",
      "The Mean Squared Error of epoch  56  is  1.6077089918405811\n",
      "The Mean Squared Error of epoch  57  is  1.60610449348234\n",
      "The Mean Squared Error of epoch  58  is  1.604516778188136\n",
      "The Mean Squared Error of epoch  59  is  1.6029456663133943\n",
      "The Mean Squared Error of epoch  60  is  1.6013909801221295\n",
      "The Mean Squared Error of epoch  61  is  1.5998525437769193\n",
      "The Mean Squared Error of epoch  62  is  1.5983301833261034\n",
      "The Mean Squared Error of epoch  63  is  1.5968237266889984\n",
      "The Mean Squared Error of epoch  64  is  1.5953330036397209\n",
      "The Mean Squared Error of epoch  65  is  1.593857845790051\n",
      "The Mean Squared Error of epoch  66  is  1.5923980865716525\n",
      "The Mean Squared Error of epoch  67  is  1.5909535612178707\n",
      "The Mean Squared Error of epoch  68  is  1.589524106745292\n",
      "The Mean Squared Error of epoch  69  is  1.5881095619351702\n",
      "The Mean Squared Error of epoch  70  is  1.5867097673148163\n",
      "The Mean Squared Error of epoch  71  is  1.5853245651390238\n",
      "The Mean Squared Error of epoch  72  is  1.5839537993715604\n",
      "The Mean Squared Error of epoch  73  is  1.582597315666773\n",
      "The Mean Squared Error of epoch  74  is  1.5812549613513214\n",
      "The Mean Squared Error of epoch  75  is  1.5799265854060667\n",
      "The Mean Squared Error of epoch  76  is  1.5786120384481168\n",
      "The Mean Squared Error of epoch  77  is  1.577311172713041\n",
      "The Mean Squared Error of epoch  78  is  1.5760238420372645\n",
      "The Mean Squared Error of epoch  79  is  1.5747499018406337\n",
      "The Mean Squared Error of epoch  80  is  1.57348920910917\n",
      "The Mean Squared Error of epoch  81  is  1.572241622377999\n",
      "The Mean Squared Error of epoch  82  is  1.5710070017144606\n",
      "The Mean Squared Error of epoch  83  is  1.5697852087014053\n",
      "The Mean Squared Error of epoch  84  is  1.568576106420665\n",
      "The Mean Squared Error of epoch  85  is  1.5673795594367046\n",
      "The Mean Squared Error of epoch  86  is  1.5661954337804516\n",
      "The Mean Squared Error of epoch  87  is  1.5650235969333004\n",
      "The Mean Squared Error of epoch  88  is  1.563863917811291\n",
      "The Mean Squared Error of epoch  89  is  1.5627162667494627\n",
      "The Mean Squared Error of epoch  90  is  1.5615805154863733\n",
      "The Mean Squared Error of epoch  91  is  1.5604565371487948\n",
      "The Mean Squared Error of epoch  92  is  1.5593442062365694\n",
      "The Mean Squared Error of epoch  93  is  1.5582433986076363\n",
      "The Mean Squared Error of epoch  94  is  1.5571539914632184\n",
      "The Mean Squared Error of epoch  95  is  1.556075863333175\n",
      "The Mean Squared Error of epoch  96  is  1.5550088940615112\n",
      "The Mean Squared Error of epoch  97  is  1.5539529647920491\n",
      "The Mean Squared Error of epoch  98  is  1.552907957954251\n",
      "The Mean Squared Error of epoch  99  is  1.5518737572492063\n",
      "The Final Value of m is :  0.7363429102170299\n",
      "The Final Value of c is :  1.0376740296772942\n",
      "The Minimum Value of MSE is :  1.5518737572492063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(3, 2),\n",
       "  (2.368, 1.842),\n",
       "  (1.906008, 1.7250800000000002),\n",
       "  (1.568377168, 1.6382179200000002),\n",
       "  (1.321716292128, 1.5733509315200003),\n",
       "  (1.141599298036288, 1.5245809353619202),\n",
       "  (1.0101582202133557, 1.4875933587725045),\n",
       "  (0.914322430752813, 1.4592319983842532),\n",
       "  (0.8445306134385433, 1.4371880125713994),\n",
       "  (0.7937885568708694, 1.4197724155136588),\n",
       "  (0.756979918494849, 1.4057496537911336),\n",
       "  (0.7303620399696894, 1.39421586560562),\n",
       "  (0.7111971298810511, 1.3845098258953263),\n",
       "  (0.6974824693375445, 1.3761478015845567),\n",
       "  (0.6877530540307348, 1.368775897392613),\n",
       "  (0.6809372244633715, 1.3621351962029167),\n",
       "  (0.6762510576775002, 1.3560362588110562),\n",
       "  (0.6731211134987517, 1.350340470174185),\n",
       "  (0.6711279224596176, 1.3449463939607762),\n",
       "  (0.6699646465172282, 1.3397797907339837),\n",
       "  (0.6694068388578133, 1.3347863161282703),\n",
       "  (0.6692903228202325, 1.329926179474236),\n",
       "  (0.6694950100554393, 1.3251702365155373),\n",
       "  (0.6699330633104255, 1.3204971311819003),\n",
       "  (0.6705402373586634, 1.3158912047596367),\n",
       "  (0.6712695447839847, 1.311340966422924),\n",
       "  (0.6720866224234772, 1.3068379744074266),\n",
       "  (0.6729663418634684, 1.3023760175738694),\n",
       "  (0.6738903299757152, 1.297950516710584),\n",
       "  (0.6748451551592485, 1.2935580865778293),\n",
       "  (0.6758210005541296, 1.2891962155367178),\n",
       "  (0.6768106934811776, 1.2848630311927356),\n",
       "  (0.6778089954653944, 1.2805571289600102),\n",
       "  (0.6788120828795836, 1.2762774466528863),\n",
       "  (0.6798171670289962, 1.2720231727470537),\n",
       "  (0.6808222162388079, 1.2677936792703728),\n",
       "  (0.6818257525579283, 1.2635884727106368),\n",
       "  (0.6828267030455764, 1.2594071581029485),\n",
       "  (0.6838242909858231, 1.2552494127581548),\n",
       "  (0.6848179563099347, 1.2511149670438424),\n",
       "  (0.6858072973845807, 1.2470035903243695),\n",
       "  (0.686792028429435, 1.2429150806748073),\n",
       "  (0.68777194836787, 1.238849257355545),\n",
       "  (0.6887469180410983, 1.234805955306362),\n",
       "  (0.6897168435402776, 1.2307850211177689),\n",
       "  (0.690681664013981, 1.2267863100829968),\n",
       "  (0.69164134274945, 1.222809684040498),\n",
       "  (0.6925958606486599, 1.218855009794721),\n",
       "  (0.693545211456217, 1.214922157959907),\n",
       "  (0.6944893982687435, 1.2110110021133358),\n",
       "  (0.6954284309816825, 1.2071214181749446),\n",
       "  (0.6963623244218384, 1.2032532839525447),\n",
       "  (0.6972910969815388, 1.1994064788081835),\n",
       "  (0.6982147696197369, 1.1955808834131276),\n",
       "  (0.6991333651315361, 1.1917763795676808),\n",
       "  (0.7000469076140651, 1.187992850068435),\n",
       "  (0.7009554220759865, 1.1842301786102223),\n",
       "  (0.7018589341520726, 1.1804882497134586),\n",
       "  (0.7027574698946386, 1.176766948670065),\n",
       "  (0.7036510556211966, 1.1730661615029854),\n",
       "  (0.7045397178032335, 1.1693857749356538),\n",
       "  (0.705423482985073, 1.1657256763687467),\n",
       "  (0.7063023777247396, 1.1620857538622673),\n",
       "  (0.7071764285509197, 1.1584658961215375),\n",
       "  (0.7080456619316938, 1.1548659924860516),\n",
       "  (0.7089101042518805, 1.151285932920429),\n",
       "  (0.7097697817966772, 1.1477256080069076),\n",
       "  (0.7106247207399067, 1.1441849089389688),\n",
       "  (0.7114749471356323, 1.1406637275157951),\n",
       "  (0.712320486912234, 1.1371619561373414),\n",
       "  (0.7131613658682862, 1.1336794877998606),\n",
       "  (0.7139976096697499, 1.1302162160917661),\n",
       "  (0.7148292438481275, 1.126772035189746),\n",
       "  (0.7156562937993184, 1.1233468398550632),\n",
       "  (0.7164787847829878, 1.1199405254300028),\n",
       "  (0.7172967419223087, 1.1165529878344234),\n",
       "  (0.7181101902039769, 1.1131841235623963),\n",
       "  (0.718919154478423, 1.1098338296789096),\n",
       "  (0.719723659460169, 1.106502003816626),\n",
       "  (0.7205237297282885, 1.1031885441726834),\n",
       "  (0.7213193897269422, 1.0998933495055325),\n",
       "  (0.7221106637659669, 1.0966163191318052),\n",
       "  (0.722897576021503, 1.093357352923211),\n",
       "  (0.7236801505366486, 1.0901163513034566),\n",
       "  (0.7244584112221324, 1.0868932152451887),\n",
       "  (0.7252323818569995, 1.083687846266957),\n",
       "  (0.7260020860893042, 1.080500146430198),\n",
       "  (0.726767547436809, 1.0773300183362358),\n",
       "  (0.7275287892876854, 1.0741773651233024),\n",
       "  (0.7282858349012151, 1.0710420904635753),\n",
       "  (0.729038707408492, 1.067924098560231),\n",
       "  (0.7297874298131212, 1.0648232941445168),\n",
       "  (0.7305320249919174, 1.0617395824728393),\n",
       "  (0.7312725156956, 1.0586728693238674),\n",
       "  (0.7320089245494856, 1.055623060995654),\n",
       "  (0.732741274054177, 1.052590064302772),\n",
       "  (0.7334695865862497, 1.0495737865734658),\n",
       "  (0.7341938843989343, 1.0465741356468214),\n",
       "  (0.7349141896227956, 1.043591019869949),\n",
       "  (0.7356305242664086, 1.0406243480951822)],\n",
       " [79.9,\n",
       "  43.4972424,\n",
       "  24.032420540646395,\n",
       "  13.62700659893446,\n",
       "  8.066259288284364,\n",
       "  5.095662793659487,\n",
       "  3.509414965827829,\n",
       "  2.6627275460350885,\n",
       "  2.210896671512855,\n",
       "  1.9697088347121352,\n",
       "  1.8407661456197855,\n",
       "  1.7715443152817563,\n",
       "  1.734031882379788,\n",
       "  1.7133090868972272,\n",
       "  1.7014430829133538,\n",
       "  1.6942261698845797,\n",
       "  1.6894340261895509,\n",
       "  1.6858963394742237,\n",
       "  1.683001446414071,\n",
       "  1.6804326931831368,\n",
       "  1.6780284093243094,\n",
       "  1.6757077479114204,\n",
       "  1.6734315658542354,\n",
       "  1.6711819038709064,\n",
       "  1.6689513089080212,\n",
       "  1.666737342427778,\n",
       "  1.6645398043972157,\n",
       "  1.662359367013109,\n",
       "  1.6601969309384512,\n",
       "  1.6580533448199037,\n",
       "  1.6559293020948456,\n",
       "  1.6538253201326376,\n",
       "  1.6517417542479542,\n",
       "  1.6496788236432358,\n",
       "  1.6476366388020274,\n",
       "  1.645615226044304,\n",
       "  1.6436145479146975,\n",
       "  1.6416345194002229,\n",
       "  1.6396750204943733,\n",
       "  1.637735905764234,\n",
       "  1.6358170115504862,\n",
       "  1.6339181613414422,\n",
       "  1.6320391697602026,\n",
       "  1.6301798455094647,\n",
       "  1.6283399935386318,\n",
       "  1.6265194166336592,\n",
       "  1.6247179165799928,\n",
       "  1.6229352950106448,\n",
       "  1.621171354022486,\n",
       "  1.619425896622174,\n",
       "  1.6176987270470051,\n",
       "  1.6159896509940122,\n",
       "  1.6142984757818195,\n",
       "  1.6126250104632445,\n",
       "  1.6109690659018512,\n",
       "  1.609330454822158,\n",
       "  1.6077089918405811,\n",
       "  1.60610449348234,\n",
       "  1.604516778188136,\n",
       "  1.6029456663133943,\n",
       "  1.6013909801221295,\n",
       "  1.5998525437769193,\n",
       "  1.5983301833261034,\n",
       "  1.5968237266889984,\n",
       "  1.5953330036397209,\n",
       "  1.593857845790051,\n",
       "  1.5923980865716525,\n",
       "  1.5909535612178707,\n",
       "  1.589524106745292,\n",
       "  1.5881095619351702,\n",
       "  1.5867097673148163,\n",
       "  1.5853245651390238,\n",
       "  1.5839537993715604,\n",
       "  1.582597315666773,\n",
       "  1.5812549613513214,\n",
       "  1.5799265854060667,\n",
       "  1.5786120384481168,\n",
       "  1.577311172713041,\n",
       "  1.5760238420372645,\n",
       "  1.5747499018406337,\n",
       "  1.57348920910917,\n",
       "  1.572241622377999,\n",
       "  1.5710070017144606,\n",
       "  1.5697852087014053,\n",
       "  1.568576106420665,\n",
       "  1.5673795594367046,\n",
       "  1.5661954337804516,\n",
       "  1.5650235969333004,\n",
       "  1.563863917811291,\n",
       "  1.5627162667494627,\n",
       "  1.5615805154863733,\n",
       "  1.5604565371487948,\n",
       "  1.5593442062365694,\n",
       "  1.5582433986076363,\n",
       "  1.5571539914632184,\n",
       "  1.556075863333175,\n",
       "  1.5550088940615112,\n",
       "  1.5539529647920491,\n",
       "  1.552907957954251,\n",
       "  1.5518737572492063])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lists for plotting purposes\n",
    "mse_list=[]\n",
    "m_list=[]\n",
    "c_list=[]\n",
    "\n",
    "X=df['x']\n",
    "y=df['y']\n",
    "gradient_descent_regularization(X, y, lr=0.01, epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using sklearn Ridge :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without train test split\n",
    "from sklearn.linear_model import Ridge\n",
    "clf = Ridge(alpha=1.0, max_iter=1000)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86486486]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50540541])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the 'm' and 'c' values came different because sklearn calculates learning rate (α) differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.23513514],\n",
       "       [3.1       ],\n",
       "       [1.37027027],\n",
       "       [1.37027027],\n",
       "       [0.50540541],\n",
       "       [4.82972973],\n",
       "       [3.96486486],\n",
       "       [5.69459459],\n",
       "       [4.82972973],\n",
       "       [3.1       ]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    1.447633\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanSquaredError(y,clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
